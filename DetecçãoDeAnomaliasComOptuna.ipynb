{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felipecampelo/isolationForestAndOptuna/blob/main/Detec%C3%A7%C3%A3oDeAnomaliasComOptuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOimh7MIH1lE"
      },
      "source": [
        "##**Testes de Detecção de Anomalias**\n",
        "\n",
        "**Autor**: Felipe Souto Campelo\n",
        "\n",
        "**Tema**: Detecção com Isolation Forest \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEHjocmUIQeX"
      },
      "source": [
        "###**Importando as Bibliotecas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc8rxveTPCwG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import joblib\n",
        "\n",
        "# pip install shap\n",
        "import shap\n",
        "\n",
        "# pip install optuna\n",
        "import optuna\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import seaborn as sns\n",
        "        \n",
        "plt.style.use(style=\"seaborn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG-NYzqxIkIm"
      },
      "source": [
        "###**Definindo as Funções**\n",
        "*   obterAmostra(Porcentagem)\n",
        "*   stringToNumeric()\n",
        "*   previsionAndMetrics(modelo, metodo, X_trainOrTest, y_trainOrTest)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piQsdsSMIsij"
      },
      "outputs": [],
      "source": [
        "def obterAmostra(Porcentagem):\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/TCC Felipe/4- Testes de Detecção/Base de Dados/PS_20174392719_1491204439457_log.csv\")\n",
        "    return df.groupby('isFraud', group_keys=False).apply(lambda x: x.sample(frac=Porcentagem)) #Amostrando os dados com 25% e mantendo a proporção de isFraud\n",
        "\n",
        "def stringToNumeric():\n",
        "    data = sampled_data.copy()\n",
        "\n",
        "    for col in data.columns: #Transformando os valores \"String\" em \"Numérico\"\n",
        "        if data[col].dtype == \"object\": #Se for String, ele é substituído por número\n",
        "            le = LabelEncoder()\n",
        "            data[col].fillna(\"None\", inplace = True)\n",
        "            le.fit(list(data[col].astype(str).values))\n",
        "            data[col] = le.transform(list(data[col].astype(str).values))\n",
        "        else: \n",
        "            data[col].fillna(-999, inplace = True)\n",
        "    \n",
        "    return data\n",
        "\n",
        "def previsionAndMetrics(modelo, metodo, trainOrTest, X_trainOrTest, y_trainOrTest):\n",
        "    y_pred = modelo.predict(X_trainOrTest.values) #Prevendo os valores\n",
        "    y_pred = mappingPredictions(y_pred)\n",
        "\n",
        "    print(\"\\nPrecisão do modelo no conjunto de \"+trainOrTest+\" (\"+metodo+\"): \", metrics.accuracy_score(y_trainOrTest, y_pred))\n",
        "    print(\"F1-SCORE BINÁRIO: \", f1_score(y_trainOrTest, y_pred, average='binary'))\n",
        "    print(\"F1-SCORE MACRO: \", f1_score(y_trainOrTest, y_pred, average='macro'))\n",
        "    print(\"F1-SCORE MICRO: \", f1_score(y_trainOrTest, y_pred, average='micro'))\n",
        "    print(\"F1-SCORE WEIGHTED: \", f1_score(y_trainOrTest, y_pred, average='weighted'))\n",
        "\n",
        "    score = -(modelo.score_samples(X_trainOrTest.values))\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_trainOrTest, score)\n",
        "    print(\"AUC metric: \", metrics.auc(fpr, tpr))\n",
        "    plt.plot(fpr, tpr)\n",
        "    \n",
        "    return y_pred\n",
        "\n",
        "def mappingPredictions(ypred):\n",
        "    # Trocando 1 para 0 e -1 para 1\n",
        "    ypred = [1 if i==-1 else 0 for i in ypred]\n",
        "\n",
        "    return ypred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzKZ4kA2JDko"
      },
      "source": [
        "###**Obtendo uma amostra dos dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4o_E0v3JMZ4"
      },
      "outputs": [],
      "source": [
        "sampled_data = obterAmostra(0.01)\n",
        "sampled_data.drop(['nameOrig','nameDest','isFlaggedFraud'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3bKZ9m4JPXq"
      },
      "source": [
        "###**Tranformando String em Numeric Values (IsolationForest exige)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yidDuc6JJVXQ"
      },
      "outputs": [],
      "source": [
        "data = stringToNumeric() "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Divisão dos dados em treino e teste**"
      ],
      "metadata": {
        "id": "lUOohzMJkb8e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWbUyoC_JeUJ"
      },
      "outputs": [],
      "source": [
        "X = pd.DataFrame(data).copy()\n",
        "X.pop('isFraud')\n",
        "y = pd.DataFrame(data['isFraud'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify = y, random_state = 42) #Divisão em treinamento e teste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW7L9fE3JY9M"
      },
      "source": [
        "###**Aplicação da Isolation Forest e do SVM**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tunando o One Class SVM\n",
        "\n",
        "#Step 1. Define an objective function to be maximized.\n",
        "def objective(trial):\n",
        "\n",
        "    # Step 2. Setup values for the hyperparameters:\n",
        "    # kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
        "    kernel = trial.suggest_categorical('kernel', ['rbf'])\n",
        "    gamma = trial.suggest_loguniform('gamma', 1e-7, 1e7)\n",
        "    # verbose = trial.suggest_int('verbose', 0, 2)\n",
        "\n",
        "    svm = OneClassSVM(kernel=kernel, nu=0.01, gamma=gamma)\n",
        "    \n",
        "    svm.fit(X_train.values)\n",
        "    y_pred = svm.predict(X_train)\n",
        "    y_pred = mappingPredictions(y_pred)\n",
        "\n",
        "    # Saving the model\n",
        "    filename = f'./svm_models/model_{trial.number}.joblib'\n",
        "    joblib.dump(svm, filename)\n",
        "\n",
        "    # Step 3: Scoring method:\n",
        "    accuracy = f1_score(y_train, y_pred, average='macro')\n",
        "    return accuracy\n",
        "\n",
        "# Step 4: Running it\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Getting the best trial\n",
        "print(f\"The best trial is : {study.best_trial}\")\n",
        "\n",
        "# Getting the best score:\n",
        "print(f\"The best value is : {study.best_value}\")\n",
        "\n",
        "# Getting the best parameters:\n",
        "print(f\"The best parameters are : {study.best_params}\")\n",
        "\n",
        "# Loading the best model\n",
        "model_svm = joblib.load(f'./svm_models/model_{study.best_trial.number}.joblib')"
      ],
      "metadata": {
        "id": "Vt_cnK8B2052",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "277a1638-8fbc-4cc4-dd7d-d283937af2a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-22 04:14:44,099]\u001b[0m A new study created in memory with name: no-name-e1f6da1f-7407-4031-8f37-efb671f47dd0\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 04:21:20,992]\u001b[0m Trial 0 finished with value: 0.21978931143278793 and parameters: {'kernel': 'rbf', 'gamma': 0.06679124765725758}. Best is trial 0 with value: 0.21978931143278793.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 04:25:20,987]\u001b[0m Trial 1 finished with value: 0.3355710862051591 and parameters: {'kernel': 'rbf', 'gamma': 1.3437842761934014e-07}. Best is trial 1 with value: 0.3355710862051591.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 04:29:14,969]\u001b[0m Trial 2 finished with value: 0.3606965550892548 and parameters: {'kernel': 'rbf', 'gamma': 1.2757816456291948e-07}. Best is trial 2 with value: 0.3606965550892548.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 04:36:03,802]\u001b[0m Trial 3 finished with value: 0.3738184251192411 and parameters: {'kernel': 'rbf', 'gamma': 0.0024141002339035096}. Best is trial 3 with value: 0.3738184251192411.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 04:41:17,974]\u001b[0m Trial 4 finished with value: 0.42952193776990855 and parameters: {'kernel': 'rbf', 'gamma': 2.336910863954316e-05}. Best is trial 4 with value: 0.42952193776990855.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 04:47:11,320]\u001b[0m Trial 5 finished with value: 0.3681190271244416 and parameters: {'kernel': 'rbf', 'gamma': 3.3423367764569664e-06}. Best is trial 4 with value: 0.42952193776990855.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 04:53:38,390]\u001b[0m Trial 6 finished with value: 0.19454491672547777 and parameters: {'kernel': 'rbf', 'gamma': 1044.6111139068003}. Best is trial 4 with value: 0.42952193776990855.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 05:00:16,871]\u001b[0m Trial 7 finished with value: 0.31501881552457706 and parameters: {'kernel': 'rbf', 'gamma': 0.0057891334564201}. Best is trial 4 with value: 0.42952193776990855.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 05:05:23,052]\u001b[0m Trial 8 finished with value: 0.343457734696563 and parameters: {'kernel': 'rbf', 'gamma': 6.546882616426726e-07}. Best is trial 4 with value: 0.42952193776990855.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 05:11:50,486]\u001b[0m Trial 9 finished with value: 0.19454491672547777 and parameters: {'kernel': 'rbf', 'gamma': 262854.0728260667}. Best is trial 4 with value: 0.42952193776990855.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 05:18:20,074]\u001b[0m Trial 10 finished with value: 0.19485259736495406 and parameters: {'kernel': 'rbf', 'gamma': 14.556559301757646}. Best is trial 4 with value: 0.42952193776990855.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 05:25:11,730]\u001b[0m Trial 11 finished with value: 0.4630425988743584 and parameters: {'kernel': 'rbf', 'gamma': 0.0007118375726163844}. Best is trial 11 with value: 0.4630425988743584.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 05:31:21,182]\u001b[0m Trial 12 finished with value: 0.29277618479959 and parameters: {'kernel': 'rbf', 'gamma': 0.00012797818831987854}. Best is trial 11 with value: 0.4630425988743584.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 05:37:15,261]\u001b[0m Trial 13 finished with value: 0.3166042094514378 and parameters: {'kernel': 'rbf', 'gamma': 8.432650876776633e-05}. Best is trial 11 with value: 0.4630425988743584.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 05:43:43,090]\u001b[0m Trial 14 finished with value: 0.19492582036470732 and parameters: {'kernel': 'rbf', 'gamma': 7.716820801618423}. Best is trial 11 with value: 0.4630425988743584.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 05:50:13,482]\u001b[0m Trial 15 finished with value: 0.2690052766549755 and parameters: {'kernel': 'rbf', 'gamma': 0.00023511506474486148}. Best is trial 11 with value: 0.4630425988743584.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 05:56:44,160]\u001b[0m Trial 16 finished with value: 0.20616983337712466 and parameters: {'kernel': 'rbf', 'gamma': 0.17806921874713155}. Best is trial 11 with value: 0.4630425988743584.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 06:01:51,029]\u001b[0m Trial 17 finished with value: 0.2756700834542773 and parameters: {'kernel': 'rbf', 'gamma': 1.838759271925885e-05}. Best is trial 11 with value: 0.4630425988743584.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 06:08:28,903]\u001b[0m Trial 18 finished with value: 0.3339385087852412 and parameters: {'kernel': 'rbf', 'gamma': 0.004387273355862593}. Best is trial 11 with value: 0.4630425988743584.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 06:14:59,207]\u001b[0m Trial 19 finished with value: 0.19454491672547777 and parameters: {'kernel': 'rbf', 'gamma': 1498611.0703484935}. Best is trial 11 with value: 0.4630425988743584.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 06:21:26,159]\u001b[0m Trial 20 finished with value: 0.19454491672547777 and parameters: {'kernel': 'rbf', 'gamma': 350.9242069129997}. Best is trial 11 with value: 0.4630425988743584.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 06:28:03,536]\u001b[0m Trial 21 finished with value: 0.32491789635116375 and parameters: {'kernel': 'rbf', 'gamma': 0.004974685831882369}. Best is trial 11 with value: 0.4630425988743584.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 06:34:53,339]\u001b[0m Trial 22 finished with value: 0.4155400195533463 and parameters: {'kernel': 'rbf', 'gamma': 0.0012943091630478998}. Best is trial 11 with value: 0.4630425988743584.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 06:40:19,386]\u001b[0m Trial 23 finished with value: 0.3707195910355569 and parameters: {'kernel': 'rbf', 'gamma': 8.795538049988645e-06}. Best is trial 11 with value: 0.4630425988743584.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 06:46:49,032]\u001b[0m Trial 24 finished with value: 0.20708009656634863 and parameters: {'kernel': 'rbf', 'gamma': 0.16125973331213406}. Best is trial 11 with value: 0.4630425988743584.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 06:53:41,422]\u001b[0m Trial 25 finished with value: 0.4699742278011838 and parameters: {'kernel': 'rbf', 'gamma': 0.0006718945526146506}. Best is trial 25 with value: 0.4699742278011838.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 06:58:57,520]\u001b[0m Trial 26 finished with value: 0.35144037146843327 and parameters: {'kernel': 'rbf', 'gamma': 1.1170976240720231e-05}. Best is trial 25 with value: 0.4699742278011838.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 07:05:30,892]\u001b[0m Trial 27 finished with value: 0.2646728300049915 and parameters: {'kernel': 'rbf', 'gamma': 0.0002574336947595131}. Best is trial 25 with value: 0.4699742278011838.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 07:12:04,313]\u001b[0m Trial 28 finished with value: 0.22502444711212266 and parameters: {'kernel': 'rbf', 'gamma': 0.05354661868881125}. Best is trial 25 with value: 0.4699742278011838.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 07:18:32,151]\u001b[0m Trial 29 finished with value: 0.19561347267042603 and parameters: {'kernel': 'rbf', 'gamma': 2.113812470575196}. Best is trial 25 with value: 0.4699742278011838.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 07:25:04,107]\u001b[0m Trial 30 finished with value: 0.23943822985345883 and parameters: {'kernel': 'rbf', 'gamma': 0.031968202650448425}. Best is trial 25 with value: 0.4699742278011838.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 07:31:55,692]\u001b[0m Trial 31 finished with value: 0.4714588598453991 and parameters: {'kernel': 'rbf', 'gamma': 0.000662799423388245}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 07:37:46,773]\u001b[0m Trial 32 finished with value: 0.3308103136084893 and parameters: {'kernel': 'rbf', 'gamma': 2.4546898744687174e-06}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 07:44:39,427]\u001b[0m Trial 33 finished with value: 0.20749430546955858 and parameters: {'kernel': 'rbf', 'gamma': 0.0006000984857568659}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 07:49:39,694]\u001b[0m Trial 34 finished with value: 0.3507271189421733 and parameters: {'kernel': 'rbf', 'gamma': 5.909188938470852e-07}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 07:55:10,284]\u001b[0m Trial 35 finished with value: 0.3776031747643626 and parameters: {'kernel': 'rbf', 'gamma': 4.137463976458778e-05}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 07:59:37,625]\u001b[0m Trial 36 finished with value: 0.3493902710904507 and parameters: {'kernel': 'rbf', 'gamma': 1.7401167497999088e-07}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 08:06:09,719]\u001b[0m Trial 37 finished with value: 0.24433779952974363 and parameters: {'kernel': 'rbf', 'gamma': 0.02737549807717954}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 08:13:01,326]\u001b[0m Trial 38 finished with value: 0.44410950220105216 and parameters: {'kernel': 'rbf', 'gamma': 0.0008617686496332772}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 08:19:29,373]\u001b[0m Trial 39 finished with value: 0.200380226458339 and parameters: {'kernel': 'rbf', 'gamma': 0.4198966227898656}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 08:26:03,515]\u001b[0m Trial 40 finished with value: 0.27032654664886013 and parameters: {'kernel': 'rbf', 'gamma': 0.013772678829211552}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 08:32:55,925]\u001b[0m Trial 41 finished with value: 0.43281531190414824 and parameters: {'kernel': 'rbf', 'gamma': 0.0009927130033127616}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 08:39:47,605]\u001b[0m Trial 42 finished with value: 0.42825858492010804 and parameters: {'kernel': 'rbf', 'gamma': 0.0010662848053847728}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 08:46:41,531]\u001b[0m Trial 43 finished with value: 0.20847283815294615 and parameters: {'kernel': 'rbf', 'gamma': 0.0005917391388523609}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 08:52:26,666]\u001b[0m Trial 44 finished with value: 0.3413235154624667 and parameters: {'kernel': 'rbf', 'gamma': 6.33271049540147e-05}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 08:58:59,759]\u001b[0m Trial 45 finished with value: 0.2935669397914543 and parameters: {'kernel': 'rbf', 'gamma': 0.008337391374597315}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 09:04:46,133]\u001b[0m Trial 46 finished with value: 0.33580119514054285 and parameters: {'kernel': 'rbf', 'gamma': 2.6001432189725787e-06}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 09:11:10,919]\u001b[0m Trial 47 finished with value: 0.19683957638649982 and parameters: {'kernel': 'rbf', 'gamma': 1.1578031463797918}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 09:17:54,359]\u001b[0m Trial 48 finished with value: 0.38796298608516366 and parameters: {'kernel': 'rbf', 'gamma': 0.0019662233886057288}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 09:24:05,047]\u001b[0m Trial 49 finished with value: 0.28727324356096673 and parameters: {'kernel': 'rbf', 'gamma': 0.00014512014593605336}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 09:30:33,191]\u001b[0m Trial 50 finished with value: 0.19454491672547777 and parameters: {'kernel': 'rbf', 'gamma': 193.51902651078683}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 09:35:50,344]\u001b[0m Trial 51 finished with value: 0.4079240205363054 and parameters: {'kernel': 'rbf', 'gamma': 2.8518381938270565e-05}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 09:42:37,408]\u001b[0m Trial 52 finished with value: 0.23918128788872092 and parameters: {'kernel': 'rbf', 'gamma': 0.0004496367834560755}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 09:49:14,042]\u001b[0m Trial 53 finished with value: 0.36543328676807724 and parameters: {'kernel': 'rbf', 'gamma': 0.002744744795098211}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 09:55:00,865]\u001b[0m Trial 54 finished with value: 0.41288040583956864 and parameters: {'kernel': 'rbf', 'gamma': 4.135265157618193e-06}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 10:00:55,228]\u001b[0m Trial 55 finished with value: 0.31590438181475927 and parameters: {'kernel': 'rbf', 'gamma': 8.692929400817065e-05}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 10:07:20,413]\u001b[0m Trial 56 finished with value: 0.19454491672547777 and parameters: {'kernel': 'rbf', 'gamma': 11844.232694298207}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 10:12:26,496]\u001b[0m Trial 57 finished with value: 0.2709480487826162 and parameters: {'kernel': 'rbf', 'gamma': 1.8473823176034052e-05}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 10:17:38,054]\u001b[0m Trial 58 finished with value: 0.3790848734973386 and parameters: {'kernel': 'rbf', 'gamma': 8.155273432191743e-07}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 10:24:06,661]\u001b[0m Trial 59 finished with value: 0.20470052913746764 and parameters: {'kernel': 'rbf', 'gamma': 0.2042080968718186}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 10:30:41,414]\u001b[0m Trial 60 finished with value: 0.28145556281216483 and parameters: {'kernel': 'rbf', 'gamma': 0.010719110250022703}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 10:37:26,197]\u001b[0m Trial 61 finished with value: 0.39984876210318293 and parameters: {'kernel': 'rbf', 'gamma': 0.001636875075817157}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 10:43:57,462]\u001b[0m Trial 62 finished with value: 0.26105124887937503 and parameters: {'kernel': 'rbf', 'gamma': 0.0002720873648444465}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n",
            "X has feature names, but OneClassSVM was fitted without feature names\n",
            "\u001b[32m[I 2022-06-22 10:50:50,744]\u001b[0m Trial 63 finished with value: 0.44863859755697044 and parameters: {'kernel': 'rbf', 'gamma': 0.0008171357150154995}. Best is trial 31 with value: 0.4714588598453991.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qq8Vcc9hSPDW"
      },
      "outputs": [],
      "source": [
        "# Tunando o Isolation Forest\n",
        "\n",
        "#Step 1. Define an objective function to be maximized.\n",
        "def objective(trial):\n",
        "    \n",
        "    # Step 2. Setup values for the hyperparameters:\n",
        "    n_estimators = trial.suggest_int('n_estimators', 1, 100)\n",
        "    # max_samples = trial.suggest_uniform('max_samples', 0.0, 1.0)\n",
        "    # contamination = trial.suggest_loguniform('contamination', 0.01)\n",
        "    # max_features = trial.suggest_uniform('max_features', 0.0, 1.0)\n",
        "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
        "    n_jobs = trial.suggest_int('n_jobs', 1, 2)\n",
        "    verbose = trial.suggest_int('verbose', 0, 2)\n",
        "\n",
        "    iforest = IsolationForest(n_estimators=n_estimators, contamination=0.01, \n",
        "                              bootstrap=bootstrap, n_jobs=n_jobs, verbose=verbose)\n",
        "    \n",
        "    iforest.fit(X_train.values)\n",
        "    y_pred = iforest.predict(X_train)\n",
        "    y_pred = mappingPredictions(y_pred)\n",
        "\n",
        "    # Saving the model\n",
        "    filename = f'./iforest_models/model_{trial.number}.joblib'\n",
        "    joblib.dump(iforest, filename)\n",
        "\n",
        "    # Step 3: Scoring method:\n",
        "    accuracy = f1_score(y_train, y_pred, average='macro')\n",
        "    return accuracy\n",
        "\n",
        "# Step 4: Running it\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=1000)\n",
        "\n",
        "# Getting the best trial\n",
        "print(f\"The best trial is : {study.best_trial}\")\n",
        "\n",
        "# Getting the best score:\n",
        "print(f\"The best value is : {study.best_value}\")\n",
        "\n",
        "# Getting the best parameters:\n",
        "print(f\"The best parameters are : {study.best_params}\")\n",
        "\n",
        "# Loading the best model\n",
        "model_iforest = joblib.load(f'./iforest_models/model_{study.best_trial.number}.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZfK2RabJk3a"
      },
      "source": [
        "###**Previsão e Métricas para IsolationForest e OneClassSVM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_dvN_2NJpt_"
      },
      "outputs": [],
      "source": [
        "y_pred_train = previsionAndMetrics(model_iforest, 'IsolationForest', 'treino', X_train, y_train)\n",
        "y_pred = previsionAndMetrics(model_iforest, 'IsolationForest', 'teste', X_test, y_test)\n",
        "y_pred_train_SVM = previsionAndMetrics(model_svm, 'OneClassSVM', 'treino', X_train, y_train)\n",
        "y_pred_SVM = previsionAndMetrics(model_svm, 'OneClassSVM', 'teste', X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B_cDJkqJufO"
      },
      "source": [
        "###**Plotando a Matriz de Confusão**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iytsGYi6J3Jt"
      },
      "outputs": [],
      "source": [
        "cf_matrix = confusion_matrix(y_test, y_pred_SVM)\n",
        "group_names = ['Verdadeiro Negativo','Falso Posivito','Falso Negativo','Verdadeiro Positivo']\n",
        "group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
        "\n",
        "labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "\n",
        "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
        "plt.show()\n",
        "\n",
        "y_pred = pd.DataFrame(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6xS4_E4Keed"
      },
      "source": [
        "###**SHAP Values para Isolation Forest**\n",
        "\n",
        "\n",
        "1.   Criando o explainer e calculando os valores SHAP\n",
        "2.   Análise dos valores SHAP para a primeira linha da previsão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VFAk_66Kx8d"
      },
      "outputs": [],
      "source": [
        "shap.initjs()\n",
        "\n",
        "explainer = shap.TreeExplainer(model_iforest) #Criando o objeto que pode calcular os valores SHAP\n",
        "shap_values = explainer.shap_values(X_test) #Calculando os valores SHAP\n",
        "\n",
        "print(\"\\n#####  Análise dos valores SHAP  #####\")\n",
        "shap.force_plot(explainer.expected_value, shap_values[1], X_test.columns, matplotlib = True, show = False) #Plotando o gráfico dos valores SHAP para a primeira linha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uiUDQQpLXwM"
      },
      "source": [
        "3.   Tabela de valores SHAP associados a cada classe em porcentagem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-IlQNFcLbfa"
      },
      "outputs": [],
      "source": [
        "print(\"\\n#####  Tabela de valores SHAP associados a cada classe  #####\")\n",
        "for col, vShap in zip(X_test.columns, shap_values[1]): #Imprimindo a contribuição de cada classe para a previsão\n",
        "    print(\"===================================================\")\n",
        "    print(col, 'tem valor SHAP associado de: ', 100*(100*vShap.round(2)/50).round(2),'%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1APFCFmLcIw"
      },
      "source": [
        "4.   Importância de cada classe para a previsão \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5fuyKr5LcP5"
      },
      "outputs": [],
      "source": [
        "print(\"\\n#####  Importância de cada classe para a previsão  #####\")\n",
        "shap.summary_plot(shap_values, X_test, plot_type=\"bar\") #Importância de cada classe para o resultado da previsão\n",
        "\n",
        "print(\"\\n#####  Análise do resultado  #####\")\n",
        "shap.summary_plot(shap_values, X_test, plot_type=\"dot\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ67yhQtLflH"
      },
      "source": [
        "5.   Contribuição de cada classe para a primeira linha de previsão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC9SdGPnLf8g"
      },
      "outputs": [],
      "source": [
        "print(\"\\n#####  Contribuição de cada classe para a primeira linha de dados  #####\")\n",
        "shap.plots._waterfall.waterfall_legacy(expected_value=explainer.expected_value[0], shap_values=shap_values[1].reshape(-1), feature_names = X_test.columns, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-dsGZnIMqRa"
      },
      "source": [
        "###**SHAP Values para One Class SVM**\n",
        "\n",
        "\n",
        "1.   Criando o explainer e calculando os valores SHAP (30min)\n",
        "2.   Análise dos valores SHAP para a primeira linha da previsão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGeZtmWrM3oj"
      },
      "outputs": [],
      "source": [
        "shap.initjs()\n",
        "\n",
        "# Uso do kmeans para acelerar o processo\n",
        "X_test_summary = shap.kmeans(X_test, 50)\n",
        "\n",
        "explainer = shap.KernelExplainer(model_svm.predict, X_test_summary) #Criando o objeto que pode calcular os valores SHAP\n",
        "shap_values = explainer.shap_values(X_test) #Calculando os valores SHAP\n",
        "\n",
        "print(\"\\n#####  Análise dos valores SHAP  #####\")\n",
        "shap.force_plot(explainer.expected_value, shap_values[1], X_test.columns, matplotlib = True, show = False) #Plotando o gráfico dos valores SHAP para a primeira linha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoflai9qM3v6"
      },
      "source": [
        "3.   Tabela de valores SHAP associados a cada classe em porcentagem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4mSPHvDM31u"
      },
      "outputs": [],
      "source": [
        "print(\"\\n#####  Tabela de valores SHAP associados a cada classe  #####\")\n",
        "for col, vShap in zip(X_test.columns, shap_values[1]): #Imprimindo a contribuição de cada classe para a previsão\n",
        "    print(\"===================================================\")\n",
        "    print(col, 'tem valor SHAP associado de: ', 100*(100*vShap.round(2)/50).round(2),'%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV7DVjXyM37P"
      },
      "source": [
        "4.   Importância de cada classe para a previsão "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr7GjAUdM4Ba"
      },
      "outputs": [],
      "source": [
        "print(\"\\n#####  Importância de cada classe para a previsão  #####\")\n",
        "shap.summary_plot(shap_values, X_test, plot_type=\"bar\") #Importância de cada classe para o resultado da previsão\n",
        "\n",
        "print(\"\\n#####  Análise do resultado  #####\")\n",
        "shap.summary_plot(shap_values, X_test, plot_type=\"dot\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-ZtmN_AM4GL"
      },
      "source": [
        "5.   Contribuição de cada classe para a primeira linha de previsão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaLrz1bmM4Mc"
      },
      "outputs": [],
      "source": [
        "print(\"\\n#####  Contribuição de cada classe para a primeira linha de dados  #####\")\n",
        "shap.plots._waterfall.waterfall_legacy(expected_value=explainer.expected_value, shap_values=shap_values[1].reshape(-1), feature_names = X_test.columns, show=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DetecçãoDeAnomaliasComOptuna.ipynb",
      "provenance": [],
      "mount_file_id": "1-3w0uPRvg0H2QtLWgPO3Ohtbk4RpPH01",
      "authorship_tag": "ABX9TyMOAlKQA50GA84qebUB9zMW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}